{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c68470a7-0d5c-4d64-bbd2-d5fdddf77f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting process_funcs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile process_funcs.py\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit as st\n",
    "\n",
    "def preprocess_data(df):\n",
    "\n",
    "    # Remove the last two columns\n",
    "    df = df.iloc[:, :-2]\n",
    "\n",
    "    # Drop rows where the second column is NaN\n",
    "    df = df.dropna(subset=[df.columns[2]])\n",
    "\n",
    "    # Select only the columns\n",
    "    cols = ['Ders','Numara', 'Ad', 'Soyad', 'PÇ1', 'PÇ2', 'PÇ3', 'PÇ4', 'PÇ5', 'PÇ6', 'PÇ7', 'PÇ8','PÇ9', 'PÇ10', 'PÇ11']\n",
    "    new_df = df[cols]\n",
    "\n",
    "    new_df = new_df.assign(**new_df[['Numara']].astype(np.int64))\n",
    "    \n",
    "    # Return the preprocessed data\n",
    "    return new_df\n",
    "\n",
    "def extract_rows_by_id(data_frames, target_numbers):\n",
    "    result_dfs = []\n",
    "\n",
    "    # Iterate through each target number\n",
    "    for target_number in target_numbers:\n",
    "        extracted_rows = []\n",
    "\n",
    "        # Iterate through each data frame\n",
    "        for df in data_frames:\n",
    "            # Filter rows based on the \"Number\" column\n",
    "            filtered_rows = df[df['Numara'] == target_number]\n",
    "\n",
    "            # Append the filtered rows to the list\n",
    "            extracted_rows.append(filtered_rows)\n",
    "\n",
    "        # Concatenate the filtered rows into a new data frame for the current target number\n",
    "        result_df = pd.concat(extracted_rows, ignore_index=True)\n",
    "\n",
    "        # Append the result data frame to the list\n",
    "        result_dfs.append(result_df)\n",
    "\n",
    "    return result_dfs\n",
    "\n",
    "def process_excel_files(file_names):\n",
    "    all_df = []\n",
    "\n",
    "    for file_name in file_names:\n",
    "        course_id = extract_pattern(str(file_name)) \n",
    "        df = pd.read_excel(file_name, sheet_name='UBYS', header=1)\n",
    "        \n",
    "        # Add the \"Course\" column to the DataFrame\n",
    "        df.insert(0, \"Ders\", course_id)\n",
    "        all_df.append(df)\n",
    "\n",
    "    return all_df\n",
    "\n",
    "# Note: I change the pattern from r'([A-Za-z]{3}\\d{3})'\n",
    "# There was an error. To avoid matchs with random lower letter combination. It happened.\n",
    "def extract_pattern(input_string):\n",
    "    pattern = r'([A-Z]{3}\\d{3})'\n",
    "    matches = re.findall(pattern, input_string)\n",
    "    result = ' '.join(matches)\n",
    "    return result\n",
    "\n",
    "def delete_empty_dfs(dataframes, target_list):\n",
    "    deleted_ids = []\n",
    "    filtered_df_list = []\n",
    "\n",
    "    for i, df in enumerate(dataframes):\n",
    "        if df.empty:\n",
    "            deleted_ids.append(target_list[i])\n",
    "        else:\n",
    "            filtered_df_list.append(df)\n",
    "    return filtered_df_list, deleted_ids\n",
    "\n",
    "def plot_bar_with_colors(data):\n",
    "    # Generate a range of colors\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(data)))\n",
    "\n",
    "    # Create a bar plot\n",
    "    plt.bar(range(len(data)), data, color=colors)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def find_missing_courses(ref_df, result_dfs):\n",
    "    missing_courses_count = {}\n",
    "    unique_courses = ref_df['Dersler'].unique()\n",
    "\n",
    "    for df in result_dfs:\n",
    "        current_courses = df['Ders'].unique()\n",
    "        missing_courses = [course for course in unique_courses if course not in current_courses]\n",
    "\n",
    "        for course in missing_courses:\n",
    "            if course in missing_courses_count:\n",
    "                missing_courses_count[course] += 1\n",
    "            else:\n",
    "                missing_courses_count[course] = 1\n",
    "\n",
    "    missing_courses_df = pd.DataFrame(list(missing_courses_count.items()), columns=['Dersler', 'MissingCount'])\n",
    "    \n",
    "    return missing_courses_df\n",
    "\n",
    "\n",
    "def calculate_means_v3(df, df_pc_dersler):\n",
    "    # Initialize a dictionary to store the mean values\n",
    "    mean_values_dict = {}\n",
    "\n",
    "    # Iterate over each performance outcome (e.g., 'PÇ1', 'PÇ2', ...)\n",
    "    for column in df_pc_dersler.columns[1:]:\n",
    "\n",
    "        # Calculate the weighted mean for the current outcome\n",
    "        total_weight = 0\n",
    "        weighted_outcomes_sum = 0\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            course_number = df.iloc[i]['Ders']\n",
    "            \n",
    "            weight = df_pc_dersler[df_pc_dersler['Dersler']==course_number][column].values[0]\n",
    "            total_weight += weight\n",
    "\n",
    "            outcome_value = df.iloc[i][column]\n",
    "            weighted_outcome = outcome_value * weight\n",
    "            weighted_outcomes_sum += weighted_outcome\n",
    "\n",
    "        # Handle the case where the total weight is zero to avoid division by zero error\n",
    "        if total_weight == 0:\n",
    "            weighted_mean = 0\n",
    "        else:\n",
    "            weighted_mean = weighted_outcomes_sum / total_weight\n",
    "\n",
    "        # Store the mean value in the dictionary\n",
    "        mean_values_dict[column] = weighted_mean\n",
    "\n",
    "    # Return the mean values dictionary\n",
    "    return mean_values_dict\n",
    "\n",
    "\n",
    "\n",
    "def process_result_dfs_v3(result_dfs, df_pc_dersler):\n",
    "    # List of column names\n",
    "    column_names = ['Numara', 'Ad', 'Soyad', 'PÇ1', 'PÇ2', 'PÇ3', 'PÇ4', 'PÇ5', 'PÇ6', 'PÇ7', 'PÇ8', 'PÇ9', 'PÇ10', 'PÇ11']\n",
    "\n",
    "    # Create an empty list to store DataFrames\n",
    "    df_list = []\n",
    "\n",
    "    # Iterate over the result dataframes\n",
    "    for i in range(len(result_dfs)):\n",
    "        if result_dfs[i].empty:\n",
    "            print('There is an empty DataFrame')\n",
    "            continue\n",
    "\n",
    "        # Create a temporary dictionary to store the values\n",
    "        temp_dict = {'Numara': result_dfs[i]['Numara'][0],\n",
    "                     'Ad': result_dfs[i]['Ad'][0],\n",
    "                     'Soyad': result_dfs[i]['Soyad'][0]}\n",
    "\n",
    "        # Calculate the means\n",
    "        means_dict = calculate_means_v3(result_dfs[i], df_pc_dersler)\n",
    "\n",
    "        # Combine the two dictionaries\n",
    "        combine_dict = {**temp_dict, **means_dict}\n",
    "\n",
    "        # Create a DataFrame from the combined dictionary\n",
    "        df_dictionary = pd.DataFrame([combine_dict])\n",
    "\n",
    "        # Append the DataFrame to the list\n",
    "        df_list.append(df_dictionary)\n",
    "\n",
    "    # Concatenate the list of DataFrames\n",
    "    if df_list:\n",
    "        df = pd.concat(df_list, ignore_index=True)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=column_names)  # Create an empty DataFrame\n",
    "\n",
    "    # Replace NaN values with zero\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def append_average_row(df):\n",
    "    # Calculate the average for the specified columns\n",
    "    average_row = {\n",
    "        'Numara': 'ORTALAMA',\n",
    "        'Ad': 'ORTALAMA',\n",
    "        'Soyad': 'ORTALAMA'\n",
    "    }\n",
    "\n",
    "    # Filter out the zero values from the DataFrame before calculating the mean\n",
    "    non_zero_df = df.replace(0, np.nan)\n",
    "\n",
    "    for col in ['PÇ1', 'PÇ2', 'PÇ3', 'PÇ4', 'PÇ5', 'PÇ6', 'PÇ7', 'PÇ8', 'PÇ9', 'PÇ10', 'PÇ11']:\n",
    "        average_row[col] = non_zero_df[col].mean()\n",
    "\n",
    "    # Create a DataFrame from the average_row dictionary\n",
    "    df_average = pd.DataFrame([average_row])\n",
    "    \n",
    "    # Replace NaN values with zero\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    # Concatenate the DataFrames\n",
    "    df = pd.concat([df, df_average], ignore_index=True)\n",
    "    \n",
    "    # Remove the students who has zero PC in any column\n",
    "    df = df[(df != 0).all(1)].reset_index(drop=True)\n",
    "    \n",
    "    # Convert it to percentage\n",
    "    df.iloc[:, 3:] = '%' + (df.iloc[:, 3:] * 100).round(1).astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "704a7fc4-b135-446d-9932-5520f1d491cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import webbrowser\n",
    "\n",
    "from process_funcs import *\n",
    "\n",
    "# Create a sidebar\n",
    "st.sidebar.title(\"About the Project\")\n",
    "\n",
    "# Write a description of the project\n",
    "st.sidebar.write(\n",
    "    '''\n",
    "    This is a custom data processing app. \n",
    "    It allows users to input multiple Excel files and generates information in the specific format.\n",
    "    '''\n",
    ")\n",
    "\n",
    "header = st.container()\n",
    "dataset = st.container()\n",
    "results = st.container()\n",
    "\n",
    "with header:\n",
    "    st.title('Program Objectives Project')\n",
    "    \n",
    "    # Instructions text\n",
    "    instructions = \"\"\"\n",
    "    #### App Instructions\n",
    "\n",
    "    This is a custom app for computing the Program Objectives for graduates. Follow these instructions to use the app:\n",
    "\n",
    "    1. Upload course evaluation reports.\n",
    "    2. Upload the graduation list.\n",
    "    3. Upload the course list file.\n",
    "    4. Click 'Run Task' button.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Display the instructions on the app\n",
    "    st.markdown(instructions)\n",
    "    \n",
    "with dataset:\n",
    "    st.subheader('Step 1 - Upload Course Evaluation Reports')\n",
    "\n",
    "    eval_files = st.file_uploader(\"Upload the Excel files (Upload ALL Reports)\", accept_multiple_files=True, key='file_uploader1')\n",
    "    st.write(f'{len(eval_files)} files are uploaded.')\n",
    "\n",
    "\n",
    "    st.subheader('Step 2 - Upload the Graduation List')\n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    # Sample DataFrame\n",
    "    data = {'Öğrenci': [],\n",
    "            'No': [],\n",
    "            'Adı': [],\n",
    "            'Soyadı': [],\n",
    "            'Durumu': [],\n",
    "            'Akademik Birim': [],\n",
    "            'Mezuniyet Yılı': [],\n",
    "            'Mezuniyet Tarihi': []\n",
    "            }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Add a button to open the DataFrame in a new tab\n",
    "    if st.button(\"Show the format of the Graduation List in New Tab\"):\n",
    "        # Save the DataFrame to an HTML file\n",
    "        df.to_html(\"dataframe.html\", index=False)\n",
    "\n",
    "        # Open the HTML file in a new tab\n",
    "        new_tab_url = \"dataframe.html\"\n",
    "        webbrowser.open_new_tab(new_tab_url)\n",
    "    ###################################\n",
    "        \n",
    "\n",
    "    # Create a file uploader\n",
    "    grad_list_file = st.file_uploader(\"Choose an Excel file\", key='file_uploader2')\n",
    "\n",
    "    # Read the uploaded file to a Pandas DataFrame\n",
    "    if grad_list_file is not None:\n",
    "        df_mezun_list = pd.read_excel(grad_list_file)\n",
    "        disp_df = df_mezun_list.style.format(precision=0, thousands='')\n",
    "        # Display the DataFrame\n",
    "        st.write(disp_df)\n",
    "\n",
    "    st.subheader('Step 3 - Upload the Course List File')\n",
    "    # Create a file uploader\n",
    "    course_list_file = st.file_uploader(\"Choose an Excel file\", key='file_uploader3')\n",
    "\n",
    "    # Read the uploaded file to a Pandas DataFrame\n",
    "    if course_list_file is not None:\n",
    "        df_pc_dersler = pd.read_excel(course_list_file)\n",
    "        \n",
    "        # Apply the extract_pattern function to each row in the 'Dersler' column\n",
    "        df_pc_dersler['Dersler'] = df_pc_dersler['Dersler'].apply(extract_pattern)\n",
    "\n",
    "        # Display the DataFrame\n",
    "        st.write(df_pc_dersler)\n",
    "    \n",
    "with results:\n",
    "    # Add a button to trigger the action\n",
    "    if st.button(\"Run Task\"):\n",
    "        \n",
    "        if eval_files is not None and grad_list_file is not None and course_list_file is not None:\n",
    "        \n",
    "        \n",
    "            # Display a waiting spinner while the task is running\n",
    "            with st.spinner(\"Running the task...\"):\n",
    "\n",
    "                # Get all excel files in the folder as list of dataframes\n",
    "                all_df = process_excel_files(eval_files)\n",
    "\n",
    "                # Preprocess these dataframes\n",
    "                processed_df = [preprocess_data(df) for df in all_df]\n",
    "\n",
    "                # Store the id's in a list\n",
    "                mezun_list = list(df_mezun_list['Öğrenci No'])\n",
    "\n",
    "                # Get result_dfs\n",
    "                result_dfs = extract_rows_by_id(processed_df, mezun_list)\n",
    "\n",
    "                # Remove the empty dataframes of students and get which ones are deleted\n",
    "                result_dfs, deleted_ids = delete_empty_dfs(result_dfs, mezun_list)\n",
    "\n",
    "                # Create a dataframe of deleted ones\n",
    "                deleted_students = df_mezun_list[df_mezun_list['Öğrenci No'].isin(deleted_ids)]\n",
    "                deleted_students = deleted_students.style.format(precision=0, thousands='')\n",
    "\n",
    "            # Task completed, remove the spinner\n",
    "            st.success(\"Task completed!\")\n",
    "        \n",
    "            # st.title('Deleted ones')\n",
    "            # st.dataframe(deleted_students)\n",
    "\n",
    "            st.title('Result')\n",
    "            df = process_result_dfs_v3(result_dfs, df_pc_dersler)\n",
    "            df = append_average_row(df)\n",
    "            st.table(df)\n",
    "\n",
    "            # Create a download button\n",
    "            def download_excel():\n",
    "                df.to_excel('dataframe.xlsx', index=False)\n",
    "                with open('dataframe.xlsx', 'rb') as f:\n",
    "                    data = f.read()\n",
    "                st.download_button(\n",
    "                    label=\"Download Excel File\",\n",
    "                    data=data,\n",
    "                    key='download_excel',\n",
    "                    file_name='dataframe.xlsx',\n",
    "                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n",
    "                )\n",
    "\n",
    "            # Call the download button function\n",
    "            download_excel()\n",
    "            \n",
    "        else: # when the files are not uploaded\n",
    "            # Display a warning message\n",
    "            st.warning(\"This is a warning message. Please upload the necessary files.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0e93f-2a0d-413e-9b66-a29ed5866f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
